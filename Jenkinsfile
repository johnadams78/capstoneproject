pipeline {
  agent any
  
  options {
    ansiColor('xterm')
    timestamps()
    disableConcurrentBuilds()
    buildDiscarder(logRotator(numToKeepStr: '10'))
    timeout(time: 90, unit: 'MINUTES')
  }
  
  environment {
    TF_IN_AUTOMATION = 'true'
    TF_CLI_ARGS = '-no-color'
    CLEANUP_MODE = 'false'
    PLAN_VALIDATED = 'false'
  }
  
  parameters {
    choice(
      name: 'ACTION',
      choices: ['plan', 'install', 'destroy'],
      description: 'Select action to perform'
    )
    booleanParam(
      name: 'DEPLOY_DATABASE',
      defaultValue: true,
      description: 'Deploy Aurora RDS MySQL database'
    )
    booleanParam(
      name: 'DEPLOY_WEB',
      defaultValue: true,
      description: 'Deploy web tier (EC2 instances + application)'
    )
    booleanParam(
      name: 'DEPLOY_MONITORING',
      defaultValue: true,
      description: 'Deploy monitoring tier (Grafana)'
    )
    booleanParam(
      name: 'AUTO_APPROVE',
      defaultValue: false,
      description: 'โ๏ธ Skip confirmation prompts (dangerous for destroy)'
    )
  }

  stages {
    
    stage('Initialize') {
      steps {
        echo '๐ง Initializing Terraform and AWS...'
        withCredentials([
          [$class: 'AmazonWebServicesCredentialsBinding', credentialsId: 'aws-credentials']
        ]) {
          sh '''
            terraform init -upgrade
            echo "โ Terraform initialized"
            echo "AWS Account: $(aws sts get-caller-identity --query Account --output text)"
            echo "AWS Region: $(aws configure get region || echo us-east-1)"
          '''
        }
      }
    }
    
    stage('Plan Infrastructure') {
      when { 
        expression { 
          params.ACTION == 'plan' || params.ACTION == 'install' || params.ACTION == 'destroy' 
        }
      }
      steps {
        script {
          if (params.ACTION == 'plan') {
            echo '๐ Creating Terraform execution plan...'
          } else if (params.ACTION == 'install') {
            echo '๐ Creating deployment execution plan...'
          } else if (params.ACTION == 'destroy') {
            echo '๐ Creating destruction execution plan...'
          }
        }
        withCredentials([
          [$class: 'AmazonWebServicesCredentialsBinding', credentialsId: 'aws-credentials'],
          string(credentialsId: 'tf-db-password', variable: 'TF_DB_PASSWORD')
        ]) {
          sh '''
            echo "๐ Validating Terraform configuration..."
            terraform validate
            
            if [ $? -ne 0 ]; then
              echo "โ Terraform configuration validation failed!"
              exit 1
            fi
            
            echo "โ Terraform configuration is valid"
            
            # Determine plan type based on ACTION
            if [ "${ACTION}" = "destroy" ]; then
              echo "๐ Creating destruction plan..."
              PLAN_FLAG="-destroy"
              PLAN_FILE="destroy-plan.tfplan"
            else
              echo "๐ Creating deployment plan..."
              PLAN_FLAG=""
              PLAN_FILE="deploy-plan.tfplan"
            fi
            
            # Create the plan with proper error handling
            set +e  # Temporarily disable exit on error
            terraform plan $PLAN_FLAG \
              -var "deploy_database=${DEPLOY_DATABASE}" \
              -var "deploy_web=${DEPLOY_WEB}" \
              -var "deploy_monitoring=${DEPLOY_MONITORING}" \
              -var "db_master_password=${TF_DB_PASSWORD}" \
              -out=$PLAN_FILE \
              -detailed-exitcode
            
            PLAN_EXIT_CODE=$?
            set -e  # Re-enable exit on error
            
            if [ $PLAN_EXIT_CODE -eq 0 ]; then
              if [ "${ACTION}" = "destroy" ]; then
                echo "๐ No resources found to destroy - infrastructure appears to be clean"
              else
                echo "๐ No changes detected - infrastructure is up to date"
              fi
            elif [ $PLAN_EXIT_CODE -eq 2 ]; then
              if [ "${ACTION}" = "destroy" ]; then
                echo "๐ Destruction plan created - resources found for removal"
              else
                echo "๐ Deployment plan created - changes detected"
              fi
            else
              echo "โ Terraform plan failed with exit code: $PLAN_EXIT_CODE"
              exit 1
            fi
            
            # For destroy action, always exit successfully since exit code 2 is expected
            if [ "${ACTION}" = "destroy" ] && [ $PLAN_EXIT_CODE -eq 2 ]; then
              echo "โ Destroy plan validation completed successfully (exit code 2 is expected for destroy operations)"
            fi
            
            echo "๐ Plan Summary:"
            set +e  # Temporarily disable exit on error for analysis
            terraform show -json $PLAN_FILE | jq -r '
              if .resource_changes then
                if env.ACTION == "destroy" then
                  "Resources to be destroyed: " + (.resource_changes | map(select(.change.actions | contains(["delete"]))) | length | tostring)
                else
                  "Resources to be created: " + (.resource_changes | map(select(.change.actions | contains(["create"]))) | length | tostring) +
                  "\nResources to be modified: " + (.resource_changes | map(select(.change.actions | contains(["update"]))) | length | tostring) +
                  "\nResources to be destroyed: " + (.resource_changes | map(select(.change.actions | contains(["delete"]))) | length | tostring)
                end
              else
                "No resource changes detected"
              end
            ' 2>/dev/null || echo "Plan summary analysis completed"
            set -e  # Re-enable exit on error
            
            # Display detailed resource list for better visibility with error handling
            if [ "${ACTION}" = "destroy" ]; then
              echo ""
              echo "๐๏ธ Resources scheduled for destruction:"
              set +e  # Temporarily disable exit on error for analysis
              terraform show -json $PLAN_FILE | jq -r '
                if .resource_changes then
                  .resource_changes | map(select(.change.actions | contains(["delete"]))) | .[] |
                  "  โข " + .type + "." + .name + " (" + .address + ")"
                else
                  "  โข No resources to destroy"
                end
              ' 2>/dev/null || echo "  โข Destruction list analysis completed"
              set -e  # Re-enable exit on error
            else
              echo ""
              echo "๐ Resources to be created/modified:"
              set +e  # Temporarily disable exit on error for analysis
              terraform show -json $PLAN_FILE | jq -r '
                if .resource_changes then
                  .resource_changes | map(select(.change.actions | contains(["create", "update"]))) | .[] |
                  "  โข " + (.change.actions[0] | ascii_upcase) + ": " + .type + "." + .name + " (" + .address + ")"
                else
                  "  โข No resources to create or modify"
                end
              ' 2>/dev/null || echo "  โข Resource list analysis completed"
              set -e  # Re-enable exit on error
            fi
            
            echo "โ Infrastructure plan created and validated successfully"
          '''
        }
        archiveArtifacts artifacts: '*plan*.tfplan', allowEmptyArchive: true
        script {
          env.PLAN_VALIDATED = 'true'
        }
      }
    }
    
    stage('Validate Plan for Deployment') {
      when { 
        expression { params.ACTION == 'install' }
      }
      steps {
        echo '๐ Pre-deployment validation...'
        script {
          // Set the validation flag at the start
          env.PLAN_VALIDATED = 'false'
          
          try {
            withCredentials([
              [$class: 'AmazonWebServicesCredentialsBinding', credentialsId: 'aws-credentials'],
              string(credentialsId: 'tf-db-password', variable: 'TF_DB_PASSWORD')
            ]) {
              sh '''
                echo "=========================================="
                echo "PRE-DEPLOYMENT VALIDATION"
                echo "=========================================="
                
                echo "๐ Validating Terraform configuration..."
                terraform validate
                
                if [ $? -ne 0 ]; then
                  echo "โ Terraform configuration validation failed!"
                  exit 1
                fi
                
                echo "โ Terraform configuration is valid"
                
                echo "๐ Creating pre-deployment validation plan..."
                
                # Allow terraform plan to return exit code 2 (changes detected)
                set +e
                terraform plan \
                  -var "deploy_database=${DEPLOY_DATABASE}" \
                  -var "deploy_web=${DEPLOY_WEB}" \
                  -var "deploy_monitoring=${DEPLOY_MONITORING}" \
                  -var "db_master_password=${TF_DB_PASSWORD}" \
                  -out=validation-plan.tfplan \
                  -detailed-exitcode
                
                PLAN_EXIT=$?
                set -e
                
                # Exit code 0 = no changes, 1 = error, 2 = changes detected
                if [ $PLAN_EXIT -eq 1 ]; then
                  echo "โ Pre-deployment planning failed!"
                  exit 1
                elif [ $PLAN_EXIT -eq 0 ]; then
                  echo "๐ No changes needed - infrastructure up to date"
                elif [ $PLAN_EXIT -eq 2 ]; then
                  echo "๐ Deployment plan validated - changes ready to apply"
                fi
                
                # Clean up
                rm -f validation-plan.tfplan
                
                echo "โ Pre-deployment validation completed successfully!"
              '''
            }
            
            // If we reach here, validation succeeded
            env.PLAN_VALIDATED = 'true'
            echo "โ Validation successful - deployment stages will proceed"
            
          } catch (Exception e) {
            env.PLAN_VALIDATED = 'false'
            echo "โ Validation failed: ${e.message}"
            error("Pre-deployment validation failed")
          }
        }
      }
    }
    
    stage('Deploy VPC') {
      when { 
        allOf {
          expression { params.ACTION == 'install' }
          expression { env.PLAN_VALIDATED == 'true' }
        }
      }
      steps {
        echo "๐ Deploying VPC and Networking..."
        echo "DEBUG: ACTION parameter value: ${params.ACTION}"
        echo "DEBUG: Should execute VPC stage: ${params.ACTION == 'install'}"
        withCredentials([
          [$class: 'AmazonWebServicesCredentialsBinding', credentialsId: 'aws-credentials']
        ]) {
          sh '''
            echo "=========================================="
            echo "STAGE 1/5: VPC AND NETWORKING DEPLOYMENT"
            echo "=========================================="
            
            echo "๐ Creating VPC infrastructure..."
            echo "- VPC (10.0.0.0/16)"
            echo "- Public Subnets (2x)"
            echo "- Private Subnets (2x)"  
            echo "- Internet Gateway"
            echo "- NAT Gateway"
            echo "- Route Tables"
            
            # Create separate plan for VPC only
            terraform plan -target=module.vpc \
              -var "deploy_database=${DEPLOY_DATABASE}" \
              -var "deploy_web=${DEPLOY_WEB}" \
              -var "deploy_monitoring=${DEPLOY_MONITORING}" \
              -out=vpc-plan.tfplan
            
            echo "โณ Applying VPC configuration..."
            terraform apply -input=false -auto-approve vpc-plan.tfplan
            
            echo "โณ Verifying VPC deployment..."
            
            # Get VPC ID with retry logic
            for i in {1..5}; do
              VPC_ID=$(terraform output -raw vpc_id 2>/dev/null || echo "")
              if [ ! -z "$VPC_ID" ] && [ "$VPC_ID" != "null" ]; then
                break
              fi
              echo "Waiting for VPC ID to be available... ($i/5)"
              sleep 10
            done
            
            echo "๐ VPC ID: $VPC_ID"
            
            if [ -z "$VPC_ID" ] || [ "$VPC_ID" = "null" ]; then
              echo "โ Failed to get VPC ID"
              exit 1
            fi
            
            # Wait for VPC to be available
            echo "โณ Waiting for VPC to be fully available..."
            aws ec2 wait vpc-available --vpc-ids $VPC_ID
            
            # Verify all subnets are created and available
            echo "โณ Verifying subnets..."
            for i in {1..12}; do
              SUBNET_COUNT=$(aws ec2 describe-subnets --filters "Name=vpc-id,Values=$VPC_ID" --query 'Subnets | length(@)')
              PUBLIC_SUBNETS=$(aws ec2 describe-subnets --filters "Name=vpc-id,Values=$VPC_ID" "Name=map-public-ip-on-launch,Values=true" --query 'Subnets | length(@)')
              PRIVATE_SUBNETS=$(aws ec2 describe-subnets --filters "Name=vpc-id,Values=$VPC_ID" "Name=map-public-ip-on-launch,Values=false" --query 'Subnets | length(@)')
              
              echo "Total subnets: $SUBNET_COUNT (Public: $PUBLIC_SUBNETS, Private: $PRIVATE_SUBNETS)"
              
              if [ "$SUBNET_COUNT" -ge "4" ] && [ "$PUBLIC_SUBNETS" -ge "2" ] && [ "$PRIVATE_SUBNETS" -ge "2" ]; then
                break
              fi
              
              echo "Waiting for all subnets to be created... ($i/12)"
              sleep 15
            done
            
            # Verify Internet Gateway and NAT Gateway
            echo "โณ Verifying gateways..."
            IGW_ID=$(aws ec2 describe-internet-gateways --filters "Name=attachment.vpc-id,Values=$VPC_ID" --query 'InternetGateways[0].InternetGatewayId' --output text)
            NAT_COUNT=$(aws ec2 describe-nat-gateways --filter "Name=vpc-id,Values=$VPC_ID" "Name=state,Values=available" --query 'NatGateways | length(@)')
            
            echo "๐ Internet Gateway: $IGW_ID"
            echo "๐ NAT Gateways: $NAT_COUNT"
            
            # Final verification
            if [ "$SUBNET_COUNT" -ge "4" ] && [ "$PUBLIC_SUBNETS" -ge "2" ] && [ "$PRIVATE_SUBNETS" -ge "2" ] && [ "$IGW_ID" != "None" ] && [ "$NAT_COUNT" -ge "1" ]; then
              echo "โ VPC and Networking deployed and verified successfully!"
              echo "๐ Summary:"
              echo "   - VPC ID: $VPC_ID"
              echo "   - Total Subnets: $SUBNET_COUNT"
              echo "   - Public Subnets: $PUBLIC_SUBNETS" 
              echo "   - Private Subnets: $PRIVATE_SUBNETS"
              echo "   - Internet Gateway: $IGW_ID"
              echo "   - NAT Gateways: $NAT_COUNT"
            else
              echo "โ VPC verification failed - initiating cleanup"
              echo "Expected: 4+ subnets (2+ public, 2+ private), 1+ IGW, 1+ NAT"
              echo "Got: $SUBNET_COUNT subnets ($PUBLIC_SUBNETS public, $PRIVATE_SUBNETS private), IGW: $IGW_ID, NAT: $NAT_COUNT"
              
              # Cleanup failed VPC resources
              echo "๐งน Cleaning up failed VPC resources..."
              if [ ! -z "$VPC_ID" ] && [ "$VPC_ID" != "null" ]; then
                terraform destroy -target=module.vpc -input=false -auto-approve \
                  -var "deploy_database=${DEPLOY_DATABASE}" \
                  -var "deploy_web=${DEPLOY_WEB}" \
                  -var "deploy_monitoring=${DEPLOY_MONITORING}" || echo "VPC cleanup failed"
              fi
              
              exit 1
            fi
          '''
        }
      }
    }
    
    stage('Deploy IAM') {
      when { 
        allOf {
          expression { params.ACTION == 'install' }
          expression { env.PLAN_VALIDATED == 'true' }
        }
      }
      steps {
        echo '๐ Deploying IAM Roles and Policies...'
        withCredentials([
          [$class: 'AmazonWebServicesCredentialsBinding', credentialsId: 'aws-credentials']
        ]) {
          sh '''
            echo "=========================================="
            echo "STAGE 2/5: IAM ROLES AND POLICIES"
            echo "=========================================="
            
            echo "๐ Creating IAM resources..."
            echo "- EC2 Service Role"
            echo "- EC2 Instance Profile"
            echo "- SSM Managed Instance Core Policy"
            
            # Create separate plan for IAM only
            terraform plan -target=module.iam \
              -var "deploy_database=${DEPLOY_DATABASE}" \
              -var "deploy_web=${DEPLOY_WEB}" \
              -var "deploy_monitoring=${DEPLOY_MONITORING}" \
              -out=iam-plan.tfplan
            
            echo "โณ Applying IAM configuration..."
            terraform apply -input=false -auto-approve iam-plan.tfplan
            
            echo "โณ Verifying IAM deployment..."
            
            # Wait for IAM role to exist and be ready
            IAM_ROLE="capstoneproject-ec2-role"
            echo "โณ Waiting for IAM role: $IAM_ROLE"
            aws iam wait role-exists --role-name $IAM_ROLE
            
            # Get role details
            ROLE_ARN=$(aws iam get-role --role-name $IAM_ROLE --query 'Role.Arn' --output text 2>/dev/null || echo "")
            echo "๐ Role ARN: $ROLE_ARN"
            
            # Wait for instance profile to exist
            INSTANCE_PROFILE="capstoneproject-ec2-profile"
            echo "โณ Waiting for instance profile: $INSTANCE_PROFILE"
            
            for i in {1..6}; do
              if aws iam get-instance-profile --instance-profile-name $INSTANCE_PROFILE >/dev/null 2>&1; then
                break
              fi
              echo "Waiting for instance profile to be ready... ($i/6)"
              sleep 10
            done
            
            # Verify instance profile details
            PROFILE_ARN=$(aws iam get-instance-profile --instance-profile-name $INSTANCE_PROFILE --query 'InstanceProfile.Arn' --output text 2>/dev/null || echo "")
            echo "๐ Instance Profile ARN: $PROFILE_ARN"
            
            # Verify role has the required policy attached
            ATTACHED_POLICIES=$(aws iam list-attached-role-policies --role-name $IAM_ROLE --query 'AttachedPolicies | length(@)')
            echo "๐ Attached Policies: $ATTACHED_POLICIES"
            
            # Final verification
            if [ ! -z "$ROLE_ARN" ] && [ ! -z "$PROFILE_ARN" ] && [ "$ATTACHED_POLICIES" -gt "0" ]; then
              echo "โ IAM resources deployed and verified successfully!"
              echo "๐ Summary:"
              echo "   - IAM Role: $IAM_ROLE"
              echo "   - Role ARN: $ROLE_ARN"
              echo "   - Instance Profile: $INSTANCE_PROFILE"  
              echo "   - Profile ARN: $PROFILE_ARN"
              echo "   - Attached Policies: $ATTACHED_POLICIES"
            else
              echo "โ IAM verification failed - initiating cleanup"
              echo "Role ARN: $ROLE_ARN"
              echo "Profile ARN: $PROFILE_ARN" 
              echo "Policies: $ATTACHED_POLICIES"
              
              # Cleanup failed IAM resources
              echo "๐งน Cleaning up failed IAM and VPC resources..."
              terraform destroy -target=module.iam -target=module.vpc -input=false -auto-approve \
                -var "deploy_database=${DEPLOY_DATABASE}" \
                -var "deploy_web=${DEPLOY_WEB}" \
                -var "deploy_monitoring=${DEPLOY_MONITORING}" || echo "IAM/VPC cleanup failed"
              
              exit 1
            fi
          '''
        }
      }
    }
    
    stage('Deploy Database') {
      when { 
        allOf {
          expression { params.ACTION == 'install' }
          expression { env.PLAN_VALIDATED == 'true' }
        }
      }
      steps {
        echo '๐๏ธ Deploying Aurora RDS Database (this takes ~5-7 minutes)...'
        withCredentials([
          [$class: 'AmazonWebServicesCredentialsBinding', credentialsId: 'aws-credentials'],
          string(credentialsId: 'tf-db-password', variable: 'TF_DB_PASSWORD')
        ]) {
          sh '''
            echo "=========================================="
            echo "STAGE 3/5: AURORA RDS DATABASE"
            echo "=========================================="
            
            echo "๐ Creating Aurora RDS cluster..."
            echo "- Aurora MySQL Cluster"
            echo "- Database Instance (db.r5.large)"
            echo "- Database Subnet Group"
            echo "- Security Groups"
            echo "- Database: capstonedb"
            
            # Create separate plan for database only  
            terraform plan -target=module.db \
              -var "deploy_database=${DEPLOY_DATABASE}" \
              -var "deploy_web=${DEPLOY_WEB}" \
              -var "deploy_monitoring=${DEPLOY_MONITORING}" \
              -var "db_master_password=${TF_DB_PASSWORD}" \
              -out=database-plan.tfplan
            
            echo "โณ Applying database configuration (this will take 5-7 minutes)..."
            terraform apply -input=false -auto-approve database-plan.tfplan
            
            echo "โณ Verifying Database deployment..."
            
            # Get cluster identifier and wait for it to be available
            CLUSTER_ID="capstoneproject-cluster"
            INSTANCE_ID="capstoneproject-instance-0"
            
            echo "โณ Waiting for Aurora cluster $CLUSTER_ID to be available..."
            echo "   This typically takes 5-7 minutes for Aurora cluster creation..."
            
            # Wait for cluster with timeout and progress updates
            for i in {1..30}; do
              CLUSTER_STATUS=$(aws rds describe-db-clusters --db-cluster-identifier $CLUSTER_ID --query 'DBClusters[0].Status' --output text 2>/dev/null || echo "not-found")
              echo "   Progress: $i/30 - Cluster status: $CLUSTER_STATUS"
              
              if [ "$CLUSTER_STATUS" = "available" ]; then
                break
              fi
              
              if [ $i -eq 30 ]; then
                echo "โ Timeout waiting for cluster to be available"
                exit 1
              fi
              
              sleep 30
            done
            
            echo "โณ Waiting for Aurora instance $INSTANCE_ID to be available..."
            aws rds wait db-instance-available --db-instance-identifier $INSTANCE_ID
            
            # Get final status and details
            CLUSTER_STATUS=$(aws rds describe-db-clusters --db-cluster-identifier $CLUSTER_ID --query 'DBClusters[0].Status' --output text)
            INSTANCE_STATUS=$(aws rds describe-db-instances --db-instance-identifier $INSTANCE_ID --query 'DBInstances[0].DBInstanceStatus' --output text)
            
            # Get endpoints
            DB_ENDPOINT=$(terraform output -raw aurora_cluster_endpoint 2>/dev/null || echo "")
            DB_NAME=$(terraform output -raw database_name 2>/dev/null || echo "capstonedb")
            
            echo "๐ Cluster Status: $CLUSTER_STATUS"
            echo "๐ Instance Status: $INSTANCE_STATUS"
            echo "๐ Database Endpoint: $DB_ENDPOINT"
            echo "๐ Database Name: $DB_NAME"
            
            # Final verification
            if [ "$CLUSTER_STATUS" = "available" ] && [ "$INSTANCE_STATUS" = "available" ] && [ ! -z "$DB_ENDPOINT" ]; then
              echo "โ Database deployed and verified successfully!"
              echo "๐ Summary:"
              echo "   - Cluster ID: $CLUSTER_ID"
              echo "   - Instance ID: $INSTANCE_ID"
              echo "   - Endpoint: $DB_ENDPOINT"
              echo "   - Database: $DB_NAME"
              echo "   - Status: Ready for connections"
            else
              echo "โ Database verification failed - initiating cleanup"
              echo "Cluster Status: $CLUSTER_STATUS"
              echo "Instance Status: $INSTANCE_STATUS"
              echo "Endpoint: $DB_ENDPOINT"
              
              # Cleanup failed database and previous resources
              echo "๐งน Cleaning up failed database and previous resources..."
              terraform destroy -target=module.db -target=module.iam -target=module.vpc -input=false -auto-approve \
                -var "deploy_database=${DEPLOY_DATABASE}" \
                -var "deploy_web=${DEPLOY_WEB}" \
                -var "deploy_monitoring=${DEPLOY_MONITORING}" \
                -var "db_master_password=${TF_DB_PASSWORD}" || echo "Database/IAM/VPC cleanup failed"
              
              exit 1
            fi
          '''
        }
      }
    }
    
    stage('Deploy Web Tier') {
      when { 
        allOf {
          expression { params.ACTION == 'install' }
          expression { env.PLAN_VALIDATED == 'true' }
        }
      }
      steps {
        echo '๐ฅ๏ธ Deploying Web Servers and Application...'
        withCredentials([
          [$class: 'AmazonWebServicesCredentialsBinding', credentialsId: 'aws-credentials']
        ]) {
          sh '''
            echo "=========================================="
            echo "STAGE 4/5: WEB TIER DEPLOYMENT"
            echo "=========================================="
            
            echo "๐ Creating Web Tier infrastructure..."
            echo "- Application Load Balancer"
            echo "- Auto Scaling Group (2-3 instances)"
            echo "- Launch Template (t3.micro)"
            echo "- Target Groups"
            echo "- Security Groups"
            echo "- Car Dealership Application"
            
            # Create separate plan for web tier only
            terraform plan -target=module.web \
              -var "deploy_database=${DEPLOY_DATABASE}" \
              -var "deploy_web=${DEPLOY_WEB}" \
              -var "deploy_monitoring=${DEPLOY_MONITORING}" \
              -out=web-plan.tfplan
            
            echo "โณ Applying web tier configuration..."
            terraform apply -input=false -auto-approve web-plan.tfplan
            
            echo "โณ Verifying Web Tier deployment..."
            
            # Get ALB details and wait for it to be active
            ALB_NAME="capstoneproject-alb"
            echo "โณ Waiting for Load Balancer: $ALB_NAME"
            
            for i in {1..10}; do
              ALB_ARN=$(aws elbv2 describe-load-balancers --names $ALB_NAME --query 'LoadBalancers[0].LoadBalancerArn' --output text 2>/dev/null || echo "")
              if [ ! -z "$ALB_ARN" ] && [ "$ALB_ARN" != "None" ]; then
                break
              fi
              echo "Waiting for ALB to be created... ($i/10)"
              sleep 15
            done
            
            echo "๐ ALB ARN: $ALB_ARN"
            
            # Wait for load balancer to be active
            echo "โณ Waiting for Load Balancer to become active..."
            aws elbv2 wait load-balancer-available --load-balancer-arns $ALB_ARN
            
            # Get ALB status and DNS
            ALB_STATE=$(aws elbv2 describe-load-balancers --load-balancer-arns $ALB_ARN --query 'LoadBalancers[0].State.Code' --output text)
            ALB_DNS=$(aws elbv2 describe-load-balancers --load-balancer-arns $ALB_ARN --query 'LoadBalancers[0].DNSName' --output text)
            
            echo "๐ ALB State: $ALB_STATE"
            echo "๐ ALB DNS: $ALB_DNS"
            
            # Wait for Auto Scaling Group to have healthy instances
            ASG_NAME="capstoneproject-asg"
            echo "โณ Waiting for Auto Scaling Group instances to be healthy..."
            echo "   This typically takes 3-5 minutes for instances to launch and pass health checks..."
            
            # Wait up to 15 minutes for healthy instances with progress updates
            for i in {1..30}; do
              TOTAL_INSTANCES=$(aws autoscaling describe-auto-scaling-groups --auto-scaling-group-names $ASG_NAME --query 'AutoScalingGroups[0].Instances | length(@)' --output text 2>/dev/null || echo "0")
              HEALTHY_COUNT=$(aws autoscaling describe-auto-scaling-groups --auto-scaling-group-names $ASG_NAME --query 'AutoScalingGroups[0].Instances[?HealthStatus==`Healthy`] | length(@)' --output text 2>/dev/null || echo "0")
              INSERVICE_COUNT=$(aws autoscaling describe-auto-scaling-groups --auto-scaling-group-names $ASG_NAME --query 'AutoScalingGroups[0].Instances[?LifecycleState==`InService`] | length(@)' --output text 2>/dev/null || echo "0")
              
              echo "   Progress: $i/30 - Total: $TOTAL_INSTANCES, Healthy: $HEALTHY_COUNT, InService: $INSERVICE_COUNT"
              
              if [ "$HEALTHY_COUNT" -ge "2" ] && [ "$INSERVICE_COUNT" -ge "2" ]; then
                break
              fi
              
              if [ $i -eq 30 ]; then
                echo "โ Timeout waiting for healthy instances"
                echo "Final status - Total: $TOTAL_INSTANCES, Healthy: $HEALTHY_COUNT, InService: $INSERVICE_COUNT"
                exit 1
              fi
              
              sleep 30
            done
            
            # Get web URLs from terraform output
            WEB_URL=$(terraform output -raw web_url 2>/dev/null || echo "")
            ALB_DNS_OUTPUT=$(terraform output -raw web_alb_dns 2>/dev/null || echo "")
            
            echo "๐ Web URL: $WEB_URL"
            echo "๐ ALB DNS (from output): $ALB_DNS_OUTPUT"
            
            # Test web application accessibility
            if [ ! -z "$WEB_URL" ] && [ "$WEB_URL" != "null" ]; then
              echo "โณ Testing web application accessibility..."
              for i in {1..6}; do
                HTTP_STATUS=$(curl -s -o /dev/null -w "%{http_code}" "$WEB_URL" --connect-timeout 10 || echo "000")
                echo "   HTTP Status: $HTTP_STATUS"
                if [ "$HTTP_STATUS" = "200" ]; then
                  break
                fi
                echo "   Waiting for web application to respond... ($i/6)"
                sleep 30
              done
            fi
            
            # Final verification
            if [ "$ALB_STATE" = "active" ] && [ "$HEALTHY_COUNT" -ge "2" ] && [ "$INSERVICE_COUNT" -ge "2" ] && [ ! -z "$WEB_URL" ]; then
              echo "โ Web tier deployed and verified successfully!"
              echo "๐ Summary:"
              echo "   - Load Balancer: $ALB_NAME ($ALB_STATE)"
              echo "   - ALB DNS: $ALB_DNS"
              echo "   - Auto Scaling Group: $ASG_NAME"
              echo "   - Healthy Instances: $HEALTHY_COUNT"
              echo "   - InService Instances: $INSERVICE_COUNT"
              echo "   - Application URL: $WEB_URL"
              if [ "$HTTP_STATUS" = "200" ]; then
                echo "   - HTTP Status: โ $HTTP_STATUS (Accessible)"
              else
                echo "   - HTTP Status: โ๏ธ $HTTP_STATUS (May still be initializing)"
              fi
            else
              echo "โ Web tier verification failed - initiating cleanup"
              echo "ALB State: $ALB_STATE"
              echo "Healthy Count: $HEALTHY_COUNT"
              echo "InService Count: $INSERVICE_COUNT"
              echo "Web URL: $WEB_URL"
              
              # Cleanup failed web tier and previous resources
              echo "๐งน Cleaning up failed web tier and previous resources..."
              terraform destroy -target=module.web -target=module.db -target=module.iam -target=module.vpc -input=false -auto-approve \
                -var "deploy_database=${DEPLOY_DATABASE}" \
                -var "deploy_web=${DEPLOY_WEB}" \
                -var "deploy_monitoring=${DEPLOY_MONITORING}" \
                -var "db_master_password=${TF_DB_PASSWORD}" || echo "Web/Database/IAM/VPC cleanup failed"
              
              exit 1
            fi
          '''
        }
      }
    }
    
    stage('Deploy Monitoring') {
      when { 
        allOf {
          expression { params.ACTION == 'install' }
          expression { env.PLAN_VALIDATED == 'true' }
        }
      }
      steps {
        echo '๐ Deploying Monitoring Stack (Grafana)...'
        withCredentials([
          [$class: 'AmazonWebServicesCredentialsBinding', credentialsId: 'aws-credentials']
        ]) {
          sh '''
            echo "=========================================="
            echo "STAGE 5/5: MONITORING STACK"
            echo "=========================================="
            
            echo "๐ Creating Monitoring infrastructure..."
            echo "- EC2 Instance (t3.micro)"
            echo "- Monitoring Dashboard (PHP/SQLite)"
            echo "- Grafana Server (Port 3000)"
            echo "- Security Groups"
            echo "- Auto-configured Services"
            
            # Create separate plan for monitoring only
            terraform plan -target=module.monitoring \
              -var "deploy_database=${DEPLOY_DATABASE}" \
              -var "deploy_web=${DEPLOY_WEB}" \
              -var "deploy_monitoring=${DEPLOY_MONITORING}" \
              -out=monitoring-plan.tfplan
            
            echo "โณ Applying monitoring configuration..."
            terraform apply -input=false -auto-approve monitoring-plan.tfplan
            
            echo "โณ Verifying Monitoring deployment..."
            
            # Get monitoring instance details with retry
            for i in {1..5}; do
              MONITORING_IP=$(terraform output -raw monitoring_public_ip 2>/dev/null || echo "")
              if [ ! -z "$MONITORING_IP" ] && [ "$MONITORING_IP" != "null" ]; then
                break
              fi
              echo "Waiting for monitoring IP to be available... ($i/5)"
              sleep 10
            done
            
            echo "๐ Monitoring Server IP: $MONITORING_IP"
            
            # Wait for EC2 instance to be running and get instance ID
            echo "โณ Finding monitoring instance..."
            for i in {1..10}; do
              INSTANCE_ID=$(aws ec2 describe-instances --filters "Name=tag:Name,Values=capstoneproject-monitoring-server" "Name=instance-state-name,Values=running" --query 'Reservations[0].Instances[0].InstanceId' --output text 2>/dev/null || echo "None")
              if [ "$INSTANCE_ID" != "None" ] && [ "$INSTANCE_ID" != "null" ] && [ ! -z "$INSTANCE_ID" ]; then
                break
              fi
              echo "Waiting for monitoring instance to be running... ($i/10)"
              sleep 15
            done
            
            echo "๐ Instance ID: $INSTANCE_ID"
            
            if [ "$INSTANCE_ID" != "None" ] && [ "$INSTANCE_ID" != "null" ] && [ ! -z "$INSTANCE_ID" ]; then
              # Wait for instance to be running
              echo "โณ Waiting for instance to be fully running..."
              aws ec2 wait instance-running --instance-ids $INSTANCE_ID
              
              # Wait for status checks to pass
              echo "โณ Waiting for instance status checks to pass..."
              aws ec2 wait instance-status-ok --instance-ids $INSTANCE_ID
              
              # Get instance status
              INSTANCE_STATE=$(aws ec2 describe-instances --instance-ids $INSTANCE_ID --query 'Reservations[0].Instances[0].State.Name' --output text)
              STATUS_CHECK=$(aws ec2 describe-instance-status --instance-ids $INSTANCE_ID --query 'InstanceStatuses[0].SystemStatus.Status' --output text 2>/dev/null || echo "unknown")
              
              echo "๐ Instance State: $INSTANCE_STATE"
              echo "๐ Status Check: $STATUS_CHECK"
              
              # Wait for HTTP services to be ready (user data script installation)
              echo "โณ Waiting for monitoring services to be installed and ready..."
              echo "   This includes Apache, PHP, Grafana installation and configuration..."
              
              for i in {1..20}; do
                # Check if monitoring dashboard is accessible
                HTTP_STATUS=$(curl -s -o /dev/null -w "%{http_code}" "http://${MONITORING_IP}" --connect-timeout 10 || echo "000")
                echo "   Progress: $i/20 - HTTP Status: $HTTP_STATUS"
                
                if [ "$HTTP_STATUS" = "200" ]; then
                  echo "   โ Monitoring dashboard is ready!"
                  break
                fi
                
                if [ $i -eq 20 ]; then
                  echo "   โ๏ธ Dashboard may still be initializing (this is normal)"
                fi
                
                sleep 30
              done
              
              # Test Grafana availability
              echo "โณ Testing Grafana availability..."
              GRAFANA_STATUS=$(curl -s -o /dev/null -w "%{http_code}" "http://${MONITORING_IP}:3000" --connect-timeout 10 || echo "000")
              echo "๐ Grafana Status: $GRAFANA_STATUS"
              
              # Get URLs from terraform output
              DASHBOARD_URL=$(terraform output -raw monitoring_dashboard_url 2>/dev/null || echo "")
              GRAFANA_URL=$(terraform output -raw grafana_dashboard_url 2>/dev/null || echo "")
              
              echo "๐ Dashboard URL: $DASHBOARD_URL"
              echo "๐ Grafana URL: $GRAFANA_URL"
              
              # Final verification
              if [ "$INSTANCE_STATE" = "running" ] && [ "$STATUS_CHECK" = "ok" ] && [ ! -z "$MONITORING_IP" ]; then
                echo "โ Monitoring deployed and verified successfully!"
                echo "๐ Summary:"
                echo "   - Instance ID: $INSTANCE_ID"
                echo "   - Public IP: $MONITORING_IP"
                echo "   - Instance State: $INSTANCE_STATE"
                echo "   - Status Checks: $STATUS_CHECK"
                echo "   - Dashboard URL: $DASHBOARD_URL"
                echo "   - Grafana URL: $GRAFANA_URL"
                echo "   - Grafana Credentials: admin/grafana123"
                if [ "$HTTP_STATUS" = "200" ]; then
                  echo "   - Dashboard Status: โ Ready"
                else
                  echo "   - Dashboard Status: โ๏ธ Still initializing"
                fi
                if [ "$GRAFANA_STATUS" = "200" ]; then
                  echo "   - Grafana Status: โ Ready"
                else
                  echo "   - Grafana Status: โ๏ธ Still initializing"
                fi
              else
                echo "โ Monitoring verification failed - initiating cleanup"
                echo "Instance State: $INSTANCE_STATE"
                echo "Status Check: $STATUS_CHECK"
                echo "Monitoring IP: $MONITORING_IP"
                
                # Cleanup all resources on monitoring failure
                echo "๐งน Cleaning up all deployed resources..."
                terraform destroy -input=false -auto-approve \
                  -var "deploy_database=${DEPLOY_DATABASE}" \
                  -var "deploy_web=${DEPLOY_WEB}" \
                  -var "deploy_monitoring=${DEPLOY_MONITORING}" \
                  -var "db_master_password=${TF_DB_PASSWORD}" || echo "Full cleanup failed"
                
                exit 1
              fi
            else
              echo "โ Monitoring verification failed - instance not found, initiating cleanup"
              
              # Cleanup all resources on monitoring failure
              echo "๐งน Cleaning up all deployed resources..."
              terraform destroy -input=false -auto-approve \
                -var "deploy_database=${DEPLOY_DATABASE}" \
                -var "deploy_web=${DEPLOY_WEB}" \
                -var "deploy_monitoring=${DEPLOY_MONITORING}" \
                -var "db_master_password=${TF_DB_PASSWORD}" || echo "Full cleanup failed"
              
              exit 1
            fi
          '''
        }
      }
    }
    
    stage('Finalize Deployment') {
      when { 
        allOf {
          expression { params.ACTION == 'install' }
          expression { env.PLAN_VALIDATED == 'true' }
        }
      }
      steps {
        echo 'โ๏ธ Finalizing deployment and applying remaining resources...'
        withCredentials([
          [$class: 'AmazonWebServicesCredentialsBinding', credentialsId: 'aws-credentials'],
          string(credentialsId: 'tf-db-password', variable: 'TF_DB_PASSWORD')
        ]) {
          sh '''
            echo "=========================================="
            echo "FINALIZATION: ENSURING ALL RESOURCES"
            echo "=========================================="
            
            echo "๐ Final comprehensive deployment..."
            echo "- Applying any remaining resources"
            echo "- Ensuring all dependencies are met"
            echo "- Refreshing terraform state"
            
            # Create final comprehensive plan to catch any missed resources
            terraform plan \
              -var "deploy_database=${DEPLOY_DATABASE}" \
              -var "deploy_web=${DEPLOY_WEB}" \
              -var "deploy_monitoring=${DEPLOY_MONITORING}" \
              -var "db_master_password=${TF_DB_PASSWORD}" \
              -out=final-plan.tfplan
            
            echo "โณ Applying final configuration..."
            terraform apply -input=false -auto-approve final-plan.tfplan
            
            echo "โณ Final verification of all components..."
            
            # Wait for final configurations to settle
            echo "Allowing time for final configurations to settle..."
            sleep 30
            
            # Verify terraform state is consistent
            echo "Refreshing terraform state..."
            terraform refresh -input=false \
              -var "deploy_database=${DEPLOY_DATABASE}" \
              -var "deploy_web=${DEPLOY_WEB}" \
              -var "deploy_monitoring=${DEPLOY_MONITORING}" \
              -var "db_master_password=${TF_DB_PASSWORD}"
            
            # Clean up plan files
            echo "Cleaning up temporary plan files..."
            rm -f vpc-plan.tfplan iam-plan.tfplan database-plan.tfplan web-plan.tfplan monitoring-plan.tfplan final-plan.tfplan validation-plan.tfplan
            
            echo "โ Deployment finalized successfully!"
            echo "๐ All infrastructure components have been deployed and verified!"
          '''
        }
      }
    }
    
    stage('Verify Infrastructure') {
      when { 
        allOf {
          expression { params.ACTION == 'install' }
          expression { env.PLAN_VALIDATED == 'true' }
        }
      }
      steps {
        echo 'โ Comprehensive Infrastructure Verification...'
        withCredentials([
          [$class: 'AmazonWebServicesCredentialsBinding', credentialsId: 'aws-credentials']
        ]) {
          sh '''
            echo "==========================================="
            echo "๐ INFRASTRUCTURE DEPLOYMENT SUMMARY"
            echo "==========================================="
            
            # Check VPC
            VPC_ID=$(terraform output -raw vpc_id 2>/dev/null || echo 'Not deployed')
            echo "๐ VPC: $VPC_ID"
            
            # Check Subnets
            if [ "$VPC_ID" != "Not deployed" ]; then
              PUBLIC_SUBNETS=$(terraform output -json public_subnets 2>/dev/null | jq -r '.[]' | wc -l)
              echo "๐ Public Subnets: $PUBLIC_SUBNETS"
            fi
            
            # Check Web Tier
            if [ "${DEPLOY_WEB}" = "true" ]; then
              WEB_URL=$(terraform output -raw web_url 2>/dev/null || echo "Not available")
              ALB_DNS=$(terraform output -raw web_alb_dns 2>/dev/null || echo "Not available")
              echo "๐ฅ๏ธ Web Application: $WEB_URL"
              echo "โ๏ธ Load Balancer DNS: $ALB_DNS"
              
              # Test web application accessibility
              if [ "$WEB_URL" != "Not available" ] && [ "$WEB_URL" != "" ]; then
                echo "๐ Testing web application accessibility..."
                HTTP_STATUS=$(curl -s -o /dev/null -w "%{http_code}" "$WEB_URL" || echo "000")
                if [ "$HTTP_STATUS" = "200" ]; then
                  echo "โ Web application is accessible (HTTP $HTTP_STATUS)"
                else
                  echo "โ๏ธ Web application returned HTTP $HTTP_STATUS (may still be initializing)"
                fi
              fi
            else
              echo "๐ฅ๏ธ Web Tier: Skipped (DEPLOY_WEB=false)"
            fi
            
            # Check Database
            if [ "${DEPLOY_DATABASE}" = "true" ]; then
              DB_ENDPOINT=$(terraform output -raw aurora_cluster_endpoint 2>/dev/null || echo "Not available")
              DB_NAME=$(terraform output -raw database_name 2>/dev/null || echo "capstonedb")
              echo "๐๏ธ Database Endpoint: $DB_ENDPOINT"
              echo "๐๏ธ Database Name: $DB_NAME"
              
              # Check database cluster status
              if [ "$DB_ENDPOINT" != "Not available" ] && [ "$DB_ENDPOINT" != "" ]; then
                CLUSTER_STATUS=$(aws rds describe-db-clusters --db-cluster-identifier capstoneproject-cluster --query 'DBClusters[0].Status' --output text 2>/dev/null || echo "unknown")
                echo "๐๏ธ Database Status: $CLUSTER_STATUS"
              fi
            else
              echo "๐๏ธ Database: Skipped (DEPLOY_DATABASE=false)"
            fi
            
            # Check Monitoring
            if [ "${DEPLOY_MONITORING}" = "true" ]; then
              MON_DASHBOARD=$(terraform output -raw monitoring_dashboard_url 2>/dev/null || echo "Not available")
              GRAFANA_URL=$(terraform output -raw grafana_dashboard_url 2>/dev/null || echo "Not available")
              MON_IP=$(terraform output -raw monitoring_public_ip 2>/dev/null || echo "Not available")
              
              echo "๐ Monitoring Dashboard: $MON_DASHBOARD"
              echo "๐ Grafana Dashboard: $GRAFANA_URL"
              echo "๐ฅ๏ธ Monitoring Server IP: $MON_IP"
              
              # Test monitoring dashboard accessibility
              if [ "$MON_DASHBOARD" != "Not available" ] && [ "$MON_DASHBOARD" != "" ]; then
                echo "๐ Testing monitoring dashboard accessibility..."
                HTTP_STATUS=$(curl -s -o /dev/null -w "%{http_code}" "$MON_DASHBOARD" || echo "000")
                if [ "$HTTP_STATUS" = "200" ]; then
                  echo "โ Monitoring dashboard is accessible (HTTP $HTTP_STATUS)"
                else
                  echo "โ๏ธ Monitoring dashboard returned HTTP $HTTP_STATUS (may still be initializing)"
                fi
              fi
            else
              echo "๐ Monitoring: Skipped (DEPLOY_MONITORING=false)"
            fi
            
            echo "==========================================="
            echo "๐ฏ DEPLOYMENT VERIFICATION COMPLETE"
            echo "==========================================="
            
            # Final status check - Resource summary
            echo "๐ Deployed Resources Summary:"
            terraform show -json | jq -r '.values.root_module.resources[] | select(.type != "data") | "\\(.type): \\(.name)"' | sort | uniq -c
            
            echo "โ All deployed resources verified successfully!"
            echo "๐ Infrastructure is ready for use!"
            echo "โ Infrastructure verification complete"
          '''
        }
      }
    }
    
    stage('๐ Deployment Success - Access Information') {
      when { 
        allOf {
          expression { params.ACTION == 'install' }
          expression { env.PLAN_VALIDATED == 'true' }
        }
      }
      steps {
        echo '๐ DEPLOYMENT SUCCESSFUL! Here are your access links...'
        withCredentials([
          [$class: 'AmazonWebServicesCredentialsBinding', credentialsId: 'aws-credentials']
        ]) {
          sh '''
            echo ""
            echo "โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ"
            echo "๐                 DEPLOYMENT SUCCESSFUL!                       ๐"
            echo "โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ"
            echo ""
            echo "๐ Your Capstone Project Infrastructure is now LIVE!"
            echo ""
            
            # Get all URLs and connection info
            VPC_ID=$(terraform output -raw vpc_id 2>/dev/null || echo 'Not available')
            WEB_URL=$(terraform output -raw web_url 2>/dev/null || echo 'Not available')
            ALB_DNS=$(terraform output -raw web_alb_dns 2>/dev/null || echo 'Not available')
            MON_DASHBOARD=$(terraform output -raw monitoring_dashboard_url 2>/dev/null || echo 'Not available')
            GRAFANA_URL=$(terraform output -raw grafana_dashboard_url 2>/dev/null || echo 'Not available')
            MON_IP=$(terraform output -raw monitoring_public_ip 2>/dev/null || echo 'Not available')
            DB_ENDPOINT=$(terraform output -raw aurora_cluster_endpoint 2>/dev/null || echo 'Not available')
            DB_NAME=$(terraform output -raw database_name 2>/dev/null || echo 'capstonedb')
            
            echo "๐ NETWORK INFORMATION:"
            echo "   โโโ VPC ID: $VPC_ID"
            echo "   โโโ Region: $(aws configure get region || echo us-east-1)"
            echo ""
            
            if [ "${DEPLOY_WEB}" = "true" ] && [ "$WEB_URL" != "Not available" ]; then
              echo "๐ฅ๏ธ  WEB APPLICATION:"
              echo "   โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ"
              echo "   โ ๐ Car Dealership Application: $WEB_URL"
              echo "   โ โ๏ธ  Load Balancer DNS:         $ALB_DNS"
              echo "   โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ"
              
              # Test web application one final time
              echo "   ๐ Testing accessibility..."
              HTTP_STATUS=$(curl -s -o /dev/null -w "%{http_code}" "$WEB_URL" --connect-timeout 15 || echo "000")
              if [ "$HTTP_STATUS" = "200" ]; then
                echo "   โ Status: READY - Application is accessible!"
              else
                echo "   โณ Status: INITIALIZING (HTTP $HTTP_STATUS) - Try again in 2-3 minutes"
              fi
              echo ""
            fi
            
            if [ "${DEPLOY_MONITORING}" = "true" ] && [ "$MON_DASHBOARD" != "Not available" ]; then
              echo "๐ MONITORING & DASHBOARDS:"
              echo "   โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ"
              echo "   โ ๐ Monitoring Dashboard:  $MON_DASHBOARD"
              echo "   โ ๐ Grafana Dashboard:     $GRAFANA_URL"
              echo "   โ ๐ฅ๏ธ  Server IP:            $MON_IP"
              echo "   โ ๐ Grafana Login:         admin / grafana123"
              echo "   โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ"
              
              # Test monitoring accessibility
              echo "   ๐ Testing accessibility..."
              MON_STATUS=$(curl -s -o /dev/null -w "%{http_code}" "$MON_DASHBOARD" --connect-timeout 15 || echo "000")
              GRAFANA_STATUS=$(curl -s -o /dev/null -w "%{http_code}" "$GRAFANA_URL" --connect-timeout 15 || echo "000")
              
              if [ "$MON_STATUS" = "200" ]; then
                echo "   โ Monitoring Dashboard: READY"
              else
                echo "   โณ Monitoring Dashboard: INITIALIZING (HTTP $MON_STATUS)"
              fi
              
              if [ "$GRAFANA_STATUS" = "200" ]; then
                echo "   โ Grafana Dashboard: READY"
              else
                echo "   โณ Grafana Dashboard: INITIALIZING (HTTP $GRAFANA_STATUS)"
              fi
              echo ""
            fi
            
            if [ "${DEPLOY_DATABASE}" = "true" ] && [ "$DB_ENDPOINT" != "Not available" ]; then
              echo "๐๏ธ  DATABASE CONNECTION:"
              echo "   โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ"
              echo "   โ ๐ Endpoint:   $DB_ENDPOINT"
              echo "   โ ๐ Database:   $DB_NAME"
              echo "   โ ๐ค Username:   admin"
              echo "   โ ๐ Password:   [Stored in Jenkins credentials: tf-db-password]"
              echo "   โ ๐ช Port:       3306"
              echo "   โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ"
              
              # Check database status
              DB_STATUS=$(aws rds describe-db-clusters --db-cluster-identifier capstoneproject-cluster --query 'DBClusters[0].Status' --output text 2>/dev/null || echo "unknown")
              echo "   โ Status: $DB_STATUS"
              echo ""
            fi
            
            echo "๐ง AWS RESOURCE INFORMATION:"
            echo "   โโโ Account ID: $(aws sts get-caller-identity --query Account --output text)"
            echo "   โโโ Region: $(aws configure get region || echo us-east-1)"
            echo "   โโโ Deployment Time: $(date)"
            echo ""
            
            echo "๐ฑ QUICK ACCESS COMMANDS:"
            echo "   โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ"
            if [ "$WEB_URL" != "Not available" ]; then
              echo "   โ Open Web App:     curl -I $WEB_URL"
            fi
            if [ "$MON_DASHBOARD" != "Not available" ]; then
              echo "   โ Check Monitoring: curl -I $MON_DASHBOARD"
            fi
            if [ "$DB_ENDPOINT" != "Not available" ]; then
              echo "   โ Test DB Connection: mysql -h $DB_ENDPOINT -u admin -p $DB_NAME"
            fi
            echo "   โ View Resources:   aws ec2 describe-instances --region $(aws configure get region || echo us-east-1)"
            echo "   โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ"
            echo ""
            
            echo "โ๏ธ  IMPORTANT NOTES:"
            echo "   โข Save these URLs - they are your access points to the infrastructure"
            echo "   โข If services show 'INITIALIZING', wait 2-3 minutes for full startup"
            echo "   โข Database password is stored securely in Jenkins credentials"
            echo "   โข Use ACTION=destroy to remove all resources and stop AWS charges"
            echo ""
            
            echo "๐ CONGRATULATIONS! Your infrastructure deployment is complete!"
            echo "โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ"
          '''
        }
      }
    }
    
    stage('Validate Destroy Plan') {
      when { 
        expression { params.ACTION == 'destroy' }
      }
      steps {
        echo '๐ Validating destroy operation...'
        withCredentials([
          [$class: 'AmazonWebServicesCredentialsBinding', credentialsId: 'aws-credentials'],
          string(credentialsId: 'tf-db-password', variable: 'TF_DB_PASSWORD')
        ]) {
          sh '''
            set -e  # Exit on error
            
            echo "=========================================="
            echo "DESTROY OPERATION VALIDATION"
            echo "=========================================="
            
            echo "๐ Validating Terraform configuration..."
            terraform validate
            
            if [ $? -ne 0 ]; then
              echo "โ Terraform configuration validation failed!"
              echo "๐จ Cannot proceed with destroy - fix configuration errors first"
              exit 1
            fi
            
            echo "โ Terraform configuration is valid"
            
            echo "๐ Checking current infrastructure state..."
            
            # Use parameter values or defaults
            DB_DEPLOY=${DEPLOY_DATABASE:-true}
            WEB_DEPLOY=${DEPLOY_WEB:-true}
            MON_DEPLOY=${DEPLOY_MONITORING:-true}
            
            echo "๐ Configuration:"
            echo "   - Deploy Database: $DB_DEPLOY"
            echo "   - Deploy Web: $WEB_DEPLOY"  
            echo "   - Deploy Monitoring: $MON_DEPLOY"
            
            # Temporarily disable exit on error for terraform refresh
            set +e
            terraform refresh -input=false \
              -var "deploy_database=$DB_DEPLOY" \
              -var "deploy_web=$WEB_DEPLOY" \
              -var "deploy_monitoring=$MON_DEPLOY" \
              -var "db_master_password=${TF_DB_PASSWORD}"
            
            REFRESH_EXIT_CODE=$?
            # Re-enable exit on error  
            set -e
            
            if [ $REFRESH_EXIT_CODE -ne 0 ]; then
              echo "โ๏ธ Warning: Terraform refresh had issues, but continuing with destroy plan..."
            fi
            
            echo "๐ Creating destroy plan..."
            
            # Temporarily disable exit on error for terraform plan
            set +e
            terraform plan -destroy \
              -var "deploy_database=$DB_DEPLOY" \
              -var "deploy_web=$WEB_DEPLOY" \
              -var "deploy_monitoring=$MON_DEPLOY" \
              -var "db_master_password=${TF_DB_PASSWORD}" \
              -out=destroy-plan.tfplan \
              -detailed-exitcode
            
            DESTROY_PLAN_EXIT_CODE=$?
            # Re-enable exit on error
            set -e
            
            if [ $DESTROY_PLAN_EXIT_CODE -eq 1 ]; then
              echo "โ Destroy plan failed!"
              echo "๐จ Cannot proceed with destruction"
              exit 1
            elif [ $DESTROY_PLAN_EXIT_CODE -eq 0 ]; then
              echo "๐ No resources found to destroy"
              echo "โ Infrastructure appears to be already clean"
            elif [ $DESTROY_PLAN_EXIT_CODE -eq 2 ]; then
              echo "๐ Destroy plan created successfully - resources found for destruction"
              
              echo "๐ Resources to be destroyed:"
              # Use set +e to ignore errors from jq commands
              set +e
              terraform show -json destroy-plan.tfplan | jq -r '
                if .resource_changes then
                  .resource_changes | map(select(.change.actions | contains(["delete"]))) | .[] |
                  "๐๏ธ  " + .type + "." + .name + " (" + .address + ")"
                else
                  "No resources to destroy"
                end
              ' 2>/dev/null || echo "๐๏ธ Resources will be destroyed (plan analysis completed)"
              
              # Count resources by type for better overview
              echo ""
              echo "๐ Destruction summary:"
              terraform show -json destroy-plan.tfplan | jq -r '
                if .resource_changes then
                  .resource_changes | map(select(.change.actions | contains(["delete"]))) | group_by(.type) | map({
                    type: .[0].type,
                    count: length
                  }) | .[] | 
                  "   - " + .type + ": " + (.count | tostring) + " resource(s)"
                else
                  "   - No resources to destroy"
                end
              ' 2>/dev/null || echo "   - Destroy summary completed"
              
              # Re-enable error checking
              set -e
            fi
            
            echo "๐ Checking for expensive resources that will be destroyed..."
            
            # Use set +e to ignore errors from AWS CLI commands
            set +e
            
            # Check for RDS clusters
            RDS_CLUSTERS=$(aws rds describe-db-clusters --query 'DBClusters[?starts_with(DBClusterIdentifier, `capstoneproject`)].DBClusterIdentifier' --output text 2>/dev/null || echo "")
            if [ ! -z "$RDS_CLUSTERS" ] && [ "$RDS_CLUSTERS" != "None" ]; then
              echo "๐ฐ WARNING: RDS clusters will be destroyed: $RDS_CLUSTERS"
            fi
            
            # Check for Load Balancers
            ALB_COUNT=$(aws elbv2 describe-load-balancers --query 'LoadBalancers[?starts_with(LoadBalancerName, `capstoneproject`)] | length(@)' --output text 2>/dev/null || echo "0")
            if [ "$ALB_COUNT" != "0" ] && [ "$ALB_COUNT" -gt "0" ] 2>/dev/null; then
              echo "๐ฐ WARNING: $ALB_COUNT Load Balancer(s) will be destroyed"
            fi
            
            # Check for NAT Gateways
            NAT_COUNT=$(aws ec2 describe-nat-gateways --filter "Name=tag:Name,Values=*capstoneproject*" --query 'NatGateways[?State==`available`] | length(@)' --output text 2>/dev/null || echo "0")
            if [ "$NAT_COUNT" != "0" ] && [ "$NAT_COUNT" -gt "0" ] 2>/dev/null; then
              echo "๐ฐ WARNING: $NAT_COUNT NAT Gateway(s) will be destroyed (saves hourly charges)"
            fi
            
            # Re-enable error checking
            set -e
            
            # Clean up destroy plan
            rm -f destroy-plan.tfplan
            
            echo "โ Destroy validation completed successfully"
            echo "โ๏ธ Review the resources listed above before confirming destruction"
            
            # Ensure script exits with success code
            exit 0
          '''
        }
        script {
          env.PLAN_VALIDATED = 'true'
        }
      }
    }
    
    stage('Destroy Confirmation') {
      when { 
        allOf {
          expression { params.ACTION == 'destroy' }
          expression { params.AUTO_APPROVE == false }
        }
      }
      steps {
        echo "๐ DEBUG: ACTION=${params.ACTION}, AUTO_APPROVE=${params.AUTO_APPROVE}"
        echo 'โ๏ธ DESTRUCTION WARNING: This will permanently destroy all infrastructure!'
        echo '๐ฐ This will stop all AWS charges for these resources'
        echo '๐ Review the destroy validation results above'
        timeout(time: 30, unit: 'MINUTES') {
          input message: '๐ฅ Are you ABSOLUTELY SURE you want to DESTROY everything? This cannot be undone!', ok: 'Yes, Destroy All Infrastructure'
        }
        script {
          env.DESTROY_CONFIRMED = 'true'
        }
      }
    }
    
    stage('Destroy Infrastructure') {
      when { 
        allOf {
          expression { params.ACTION == 'destroy' }
          anyOf {
            expression { params.AUTO_APPROVE == true }
            expression { env.DESTROY_CONFIRMED == 'true' }
          }
        }
      }
      steps {
        echo "๐ DEBUG: ACTION=${params.ACTION}, AUTO_APPROVE=${params.AUTO_APPROVE}, DESTROY_CONFIRMED=${env.DESTROY_CONFIRMED}"
        echo '๐ฅ Destroying all infrastructure...'
        withCredentials([
          [$class: 'AmazonWebServicesCredentialsBinding', credentialsId: 'aws-credentials'],
          string(credentialsId: 'tf-db-password', variable: 'TF_DB_PASSWORD')
        ]) {
          sh '''
            echo "=========================================="
            echo "๐๏ธ  INFRASTRUCTURE DESTRUCTION"
            echo "=========================================="
            
            echo "๐ฅ Starting systematic infrastructure destruction..."
            
            # Use parameter values or defaults
            DB_DEPLOY=${DEPLOY_DATABASE:-true}
            WEB_DEPLOY=${DEPLOY_WEB:-true}
            MON_DEPLOY=${DEPLOY_MONITORING:-true}
            
            echo "๐ Destroy Configuration:"
            echo "   - Deploy Database: $DB_DEPLOY"
            echo "   - Deploy Web: $WEB_DEPLOY"  
            echo "   - Deploy Monitoring: $MON_DEPLOY"
            
            # =====================================================
            # STEP 1: Force cleanup AWS resources directly (handles out-of-sync state)
            # =====================================================
            echo ""
            echo "๐ STEP 1: Pre-Terraform AWS Resource Cleanup"
            echo "============================================="
            echo "This ensures resources are deleted even if Terraform state is out of sync..."
            
            set +e  # Don't exit on errors during cleanup
            
            # 1. Delete Auto Scaling Groups first (they block instance termination)
            echo "๐ Checking for Auto Scaling Groups..."
            ASG_LIST=$(aws autoscaling describe-auto-scaling-groups --query "AutoScalingGroups[?contains(AutoScalingGroupName, 'capstoneproject')].AutoScalingGroupName" --output text 2>/dev/null || echo "")
            if [ ! -z "$ASG_LIST" ]; then
              for asg in $ASG_LIST; do
                echo "   ๐๏ธ Deleting ASG: $asg"
                aws autoscaling update-auto-scaling-group --auto-scaling-group-name "$asg" --min-size 0 --desired-capacity 0 2>/dev/null
                aws autoscaling delete-auto-scaling-group --auto-scaling-group-name "$asg" --force-delete 2>/dev/null
              done
              echo "   โณ Waiting for ASG deletion..."
              sleep 30
            else
              echo "   โ No Auto Scaling Groups found"
            fi
            
            # 2. Delete Load Balancers and Target Groups
            echo "๐ Checking for Load Balancers..."
            ALB_ARNS=$(aws elbv2 describe-load-balancers --query "LoadBalancers[?contains(LoadBalancerName, 'capstoneproject')].LoadBalancerArn" --output text 2>/dev/null || echo "")
            if [ ! -z "$ALB_ARNS" ]; then
              for alb in $ALB_ARNS; do
                echo "   ๐๏ธ Deleting Load Balancer: $alb"
                # First delete listeners
                LISTENERS=$(aws elbv2 describe-listeners --load-balancer-arn "$alb" --query 'Listeners[*].ListenerArn' --output text 2>/dev/null || echo "")
                for listener in $LISTENERS; do
                  aws elbv2 delete-listener --listener-arn "$listener" 2>/dev/null
                done
                aws elbv2 delete-load-balancer --load-balancer-arn "$alb" 2>/dev/null
              done
              echo "   โณ Waiting for ALB deletion..."
              sleep 30
            else
              echo "   โ No Load Balancers found"
            fi
            
            # Delete Target Groups
            echo "๐ Checking for Target Groups..."
            TG_ARNS=$(aws elbv2 describe-target-groups --query "TargetGroups[?contains(TargetGroupName, 'capstoneproject')].TargetGroupArn" --output text 2>/dev/null || echo "")
            if [ ! -z "$TG_ARNS" ]; then
              for tg in $TG_ARNS; do
                echo "   ๐๏ธ Deleting Target Group: $tg"
                aws elbv2 delete-target-group --target-group-arn "$tg" 2>/dev/null
              done
            else
              echo "   โ No Target Groups found"
            fi
            
            # 3. Terminate EC2 Instances
            echo "๐ Checking for EC2 Instances..."
            INSTANCE_IDS=$(aws ec2 describe-instances --filters "Name=tag:Name,Values=*capstoneproject*" "Name=instance-state-name,Values=running,pending,stopping,stopped" --query 'Reservations[*].Instances[*].InstanceId' --output text 2>/dev/null || echo "")
            if [ ! -z "$INSTANCE_IDS" ]; then
              echo "   ๐๏ธ Terminating instances: $INSTANCE_IDS"
              aws ec2 terminate-instances --instance-ids $INSTANCE_IDS 2>/dev/null
              echo "   โณ Waiting for instance termination..."
              aws ec2 wait instance-terminated --instance-ids $INSTANCE_IDS 2>/dev/null || sleep 60
            else
              echo "   โ No EC2 Instances found"
            fi
            
            # 4. Delete RDS Instances and Clusters
            echo "๐ Checking for RDS resources..."
            DB_INSTANCES=$(aws rds describe-db-instances --query "DBInstances[?contains(DBInstanceIdentifier, 'capstoneproject')].DBInstanceIdentifier" --output text 2>/dev/null || echo "")
            if [ ! -z "$DB_INSTANCES" ]; then
              for db in $DB_INSTANCES; do
                echo "   ๐๏ธ Deleting RDS Instance: $db"
                aws rds delete-db-instance --db-instance-identifier "$db" --skip-final-snapshot --delete-automated-backups 2>/dev/null
              done
            fi
            
            DB_CLUSTERS=$(aws rds describe-db-clusters --query "DBClusters[?contains(DBClusterIdentifier, 'capstoneproject')].DBClusterIdentifier" --output text 2>/dev/null || echo "")
            if [ ! -z "$DB_CLUSTERS" ]; then
              for cluster in $DB_CLUSTERS; do
                echo "   ๐๏ธ Deleting RDS Cluster: $cluster"
                aws rds delete-db-cluster --db-cluster-identifier "$cluster" --skip-final-snapshot --delete-automated-backups 2>/dev/null
              done
              echo "   โณ Waiting for RDS deletion (this can take several minutes)..."
              sleep 120
            else
              echo "   โ No RDS Clusters found"
            fi
            
            # 5. Delete NAT Gateways (must be deleted before EIPs and subnets)
            echo "๐ Checking for NAT Gateways..."
            NAT_IDS=$(aws ec2 describe-nat-gateways --filter "Name=tag:Name,Values=*capstoneproject*" "Name=state,Values=available,pending" --query 'NatGateways[*].NatGatewayId' --output text 2>/dev/null || echo "")
            if [ ! -z "$NAT_IDS" ]; then
              for nat in $NAT_IDS; do
                echo "   ๐๏ธ Deleting NAT Gateway: $nat"
                aws ec2 delete-nat-gateway --nat-gateway-id "$nat" 2>/dev/null
              done
              echo "   โณ Waiting for NAT Gateway deletion..."
              for nat in $NAT_IDS; do
                aws ec2 wait nat-gateway-deleted --nat-gateway-ids "$nat" 2>/dev/null || sleep 60
              done
            else
              echo "   โ No NAT Gateways found"
            fi
            
            # 6. Release Elastic IPs
            echo "๐ Checking for Elastic IPs..."
            EIP_ALLOCS=$(aws ec2 describe-addresses --filters "Name=tag:Name,Values=*capstoneproject*" --query 'Addresses[*].AllocationId' --output text 2>/dev/null || echo "")
            if [ ! -z "$EIP_ALLOCS" ]; then
              for eip in $EIP_ALLOCS; do
                echo "   ๐๏ธ Releasing EIP: $eip"
                aws ec2 release-address --allocation-id "$eip" 2>/dev/null
              done
            else
              echo "   โ No Elastic IPs found"
            fi
            
            # 7. Delete Security Groups (except default)
            echo "๐ Checking for Security Groups..."
            VPC_ID=$(aws ec2 describe-vpcs --filters "Name=tag:Name,Values=*capstoneproject*" --query 'Vpcs[0].VpcId' --output text 2>/dev/null || echo "None")
            if [ "$VPC_ID" != "None" ] && [ ! -z "$VPC_ID" ]; then
              SG_IDS=$(aws ec2 describe-security-groups --filters "Name=vpc-id,Values=$VPC_ID" --query "SecurityGroups[?GroupName!='default'].GroupId" --output text 2>/dev/null || echo "")
              if [ ! -z "$SG_IDS" ]; then
                for sg in $SG_IDS; do
                  echo "   ๐๏ธ Deleting Security Group: $sg"
                  aws ec2 delete-security-group --group-id "$sg" 2>/dev/null || echo "      โ๏ธ Could not delete $sg (may have dependencies)"
                done
              fi
            fi
            
            # 8. Delete Subnets
            echo "๐ Checking for Subnets..."
            if [ "$VPC_ID" != "None" ] && [ ! -z "$VPC_ID" ]; then
              SUBNET_IDS=$(aws ec2 describe-subnets --filters "Name=vpc-id,Values=$VPC_ID" --query 'Subnets[*].SubnetId' --output text 2>/dev/null || echo "")
              if [ ! -z "$SUBNET_IDS" ]; then
                for subnet in $SUBNET_IDS; do
                  echo "   ๐๏ธ Deleting Subnet: $subnet"
                  aws ec2 delete-subnet --subnet-id "$subnet" 2>/dev/null || echo "      โ๏ธ Could not delete $subnet"
                done
              fi
            fi
            
            # 9. Delete Internet Gateway
            echo "๐ Checking for Internet Gateways..."
            if [ "$VPC_ID" != "None" ] && [ ! -z "$VPC_ID" ]; then
              IGW_ID=$(aws ec2 describe-internet-gateways --filters "Name=attachment.vpc-id,Values=$VPC_ID" --query 'InternetGateways[0].InternetGatewayId' --output text 2>/dev/null || echo "None")
              if [ "$IGW_ID" != "None" ] && [ ! -z "$IGW_ID" ]; then
                echo "   ๐๏ธ Detaching and deleting IGW: $IGW_ID"
                aws ec2 detach-internet-gateway --internet-gateway-id "$IGW_ID" --vpc-id "$VPC_ID" 2>/dev/null
                aws ec2 delete-internet-gateway --internet-gateway-id "$IGW_ID" 2>/dev/null
              fi
            fi
            
            # 10. Delete Route Tables (except main)
            echo "๐ Checking for Route Tables..."
            if [ "$VPC_ID" != "None" ] && [ ! -z "$VPC_ID" ]; then
              RT_IDS=$(aws ec2 describe-route-tables --filters "Name=vpc-id,Values=$VPC_ID" --query 'RouteTables[?Associations[0].Main!=`true`].RouteTableId' --output text 2>/dev/null || echo "")
              if [ ! -z "$RT_IDS" ]; then
                for rt in $RT_IDS; do
                  # First disassociate
                  ASSOC_IDS=$(aws ec2 describe-route-tables --route-table-ids "$rt" --query 'RouteTables[0].Associations[?!Main].RouteTableAssociationId' --output text 2>/dev/null || echo "")
                  for assoc in $ASSOC_IDS; do
                    aws ec2 disassociate-route-table --association-id "$assoc" 2>/dev/null
                  done
                  echo "   ๐๏ธ Deleting Route Table: $rt"
                  aws ec2 delete-route-table --route-table-id "$rt" 2>/dev/null || echo "      โ๏ธ Could not delete $rt"
                done
              fi
            fi
            
            # 11. Delete VPC
            echo "๐ Checking for VPC..."
            if [ "$VPC_ID" != "None" ] && [ ! -z "$VPC_ID" ]; then
              echo "   ๐๏ธ Deleting VPC: $VPC_ID"
              aws ec2 delete-vpc --vpc-id "$VPC_ID" 2>/dev/null || echo "      โ๏ธ Could not delete VPC (may have remaining dependencies)"
            else
              echo "   โ No VPC found"
            fi
            
            # 12. Delete IAM Resources
            echo "๐ Checking for IAM resources..."
            if aws iam get-instance-profile --instance-profile-name "capstoneproject-ec2-profile" 2>/dev/null; then
              echo "   ๐๏ธ Removing role from instance profile..."
              aws iam remove-role-from-instance-profile --instance-profile-name "capstoneproject-ec2-profile" --role-name "capstoneproject-ec2-role" 2>/dev/null
              echo "   ๐๏ธ Deleting instance profile..."
              aws iam delete-instance-profile --instance-profile-name "capstoneproject-ec2-profile" 2>/dev/null
            fi
            
            if aws iam get-role --role-name "capstoneproject-ec2-role" 2>/dev/null; then
              echo "   ๐๏ธ Detaching policies from role..."
              POLICIES=$(aws iam list-attached-role-policies --role-name "capstoneproject-ec2-role" --query 'AttachedPolicies[*].PolicyArn' --output text 2>/dev/null || echo "")
              for policy in $POLICIES; do
                aws iam detach-role-policy --role-name "capstoneproject-ec2-role" --policy-arn "$policy" 2>/dev/null
              done
              echo "   ๐๏ธ Deleting IAM role..."
              aws iam delete-role --role-name "capstoneproject-ec2-role" 2>/dev/null
            fi
            
            # 13. Delete DB Subnet Group
            echo "๐ Checking for DB Subnet Groups..."
            aws rds delete-db-subnet-group --db-subnet-group-name "capstoneproject-db-subnet-group" 2>/dev/null && echo "   ๐๏ธ Deleted DB Subnet Group" || echo "   โ No DB Subnet Group found"
            
            set -e  # Re-enable exit on errors
            
            echo ""
            echo "โ Pre-Terraform cleanup completed!"
            echo ""
            
            # =====================================================
            # STEP 2: Run Terraform Destroy (cleanup any remaining state)
            # =====================================================
            echo "๐ STEP 2: Terraform State Cleanup"
            echo "=================================="
            
            # Final validation before destruction
            echo "๐ Validating Terraform configuration..."
            terraform validate || echo "โ๏ธ Validation had issues, continuing anyway..."
            
            # Refresh state to sync with actual AWS resources
            echo "๐ Refreshing Terraform state..."
            set +e
            terraform refresh -input=false \
              -var "deploy_database=$DB_DEPLOY" \
              -var "deploy_web=$WEB_DEPLOY" \
              -var "deploy_monitoring=$MON_DEPLOY" \
              -var "db_master_password=${TF_DB_PASSWORD}" 2>/dev/null
            set -e
            
            # Execute terraform destroy (will cleanup any remaining tracked resources)
            echo "๐ Executing Terraform destroy..."
            set +e
            terraform destroy -input=false -auto-approve \
              -var "deploy_database=$DB_DEPLOY" \
              -var "deploy_web=$WEB_DEPLOY" \
              -var "deploy_monitoring=$MON_DEPLOY" \
              -var "db_master_password=${TF_DB_PASSWORD}"
            
            DESTROY_EXIT_CODE=$?
            set -e
            
            if [ $DESTROY_EXIT_CODE -eq 0 ]; then
              echo "โ Terraform destruction completed successfully"
            else
              echo "โ๏ธ Terraform destroy had issues (exit code: $DESTROY_EXIT_CODE)"
              echo "   This is often OK since resources were already cleaned up manually"
            fi
            
            # =====================================================
            # STEP 3: Final Verification
            # =====================================================
            echo ""
            echo "๐ STEP 3: Final Verification"
            echo "============================="
            sleep 10
            
            # Check if major resources still exist
            REMAINING_VPC=$(aws ec2 describe-vpcs --filters "Name=tag:Name,Values=*capstoneproject*" --query 'Vpcs[0].VpcId' --output text 2>/dev/null || echo "None")
            REMAINING_RDS=$(aws rds describe-db-clusters --query "DBClusters[?contains(DBClusterIdentifier, 'capstoneproject')] | length(@)" --output text 2>/dev/null || echo "0")
            REMAINING_ALB=$(aws elbv2 describe-load-balancers --query "LoadBalancers[?contains(LoadBalancerName, 'capstoneproject')] | length(@)" --output text 2>/dev/null || echo "0")
            REMAINING_EC2=$(aws ec2 describe-instances --filters "Name=tag:Name,Values=*capstoneproject*" "Name=instance-state-name,Values=running,pending" --query 'Reservations | length(@)' --output text 2>/dev/null || echo "0")
            
            echo ""
            echo "๐ Destruction Summary:"
            echo "   - VPC: $([ "$REMAINING_VPC" = "None" ] || [ -z "$REMAINING_VPC" ] && echo "โ Destroyed" || echo "โ๏ธ May still exist: $REMAINING_VPC")"
            echo "   - RDS Clusters: $([ "$REMAINING_RDS" = "0" ] && echo "โ Destroyed" || echo "โ๏ธ $REMAINING_RDS still exist")"
            echo "   - Load Balancers: $([ "$REMAINING_ALB" = "0" ] && echo "โ Destroyed" || echo "โ๏ธ $REMAINING_ALB still exist")"
            echo "   - EC2 Instances: $([ "$REMAINING_EC2" = "0" ] && echo "โ Destroyed" || echo "โ๏ธ $REMAINING_EC2 still running")"
            
            if ([ "$REMAINING_VPC" = "None" ] || [ -z "$REMAINING_VPC" ]) && [ "$REMAINING_RDS" = "0" ] && [ "$REMAINING_ALB" = "0" ] && [ "$REMAINING_EC2" = "0" ]; then
              echo ""
              echo "๐ ============================================="
              echo "๐  ALL INFRASTRUCTURE DESTROYED SUCCESSFULLY!"
              echo "๐ ============================================="
              echo "๐ฐ AWS charges for this project have stopped"
            else
              echo ""
              echo "โ๏ธ Some resources may still exist - please verify in AWS console"
              echo "   You may need to wait a few minutes for all resources to be fully deleted"
            fi
          '''
        }
        archiveArtifacts artifacts: '*.txt', allowEmptyArchive: true
      }
    }
  }

  post {
    always {
      echo "Pipeline completed: ${currentBuild.currentResult}"
      echo "Build #${env.BUILD_NUMBER} - Duration: ${currentBuild.durationString}"
      
      // Cleanup temporary plan files
      script {
        try {
          sh '''
            echo "๐งน Cleaning up temporary files..."
            rm -f vpc-plan.tfplan iam-plan.tfplan database-plan.tfplan web-plan.tfplan monitoring-plan.tfplan final-plan.tfplan validation-plan.tfplan destroy-plan.tfplan deploy-plan.tfplan tfplan
            echo "โ Temporary files cleaned up"
          '''
        } catch (Exception e) {
          echo "โ๏ธ Warning: Could not clean up temporary files: ${e.getMessage()}"
        }
      }
    }
    
    success {
      echo "โ Pipeline completed successfully!"
      echo "๐ All infrastructure deployed and verified!"
    }
    
    failure {
      echo "โ Pipeline failed. Check logs for details."
      
      // Emergency cleanup for failed installations
      script {
        if (params.ACTION == 'install') {
          echo "๐จ EMERGENCY CLEANUP: Pipeline failed during installation"
          echo "โ๏ธ Attempting to destroy any partially created resources..."
          
          try {
            withCredentials([
              [$class: 'AmazonWebServicesCredentialsBinding', credentialsId: 'aws-credentials'],
              string(credentialsId: 'tf-db-password', variable: 'TF_DB_PASSWORD')
            ]) {
              timeout(time: 20, unit: 'MINUTES') {
                sh '''
                  echo "๐ Checking for partially created resources..."
                  
                  # Initialize terraform if needed
                  if [ ! -d ".terraform" ]; then
                    echo "Initializing Terraform for cleanup..."
                    terraform init -upgrade
                  fi
                  
                  # Get current state
                  echo "๐ Current terraform state:"
                  terraform state list || echo "No state file found"
                  
                  # Check for AWS resources that might have been created
                  echo "๐ Scanning for AWS resources with project tag..."
                  
                  # List potential resources by tag
                  VPC_ID=$(aws ec2 describe-vpcs --filters "Name=tag:Name,Values=capstoneproject-vpc" --query 'Vpcs[0].VpcId' --output text 2>/dev/null || echo "None")
                  ALB_ARN=$(aws elbv2 describe-load-balancers --names "capstoneproject-alb" --query 'LoadBalancers[0].LoadBalancerArn' --output text 2>/dev/null || echo "None")
                  DB_CLUSTER=$(aws rds describe-db-clusters --db-cluster-identifier "capstoneproject-cluster" --query 'DBClusters[0].DBClusterIdentifier' --output text 2>/dev/null || echo "None")
                  
                  echo "Found resources:"
                  echo "- VPC: $VPC_ID"
                  echo "- ALB: $ALB_ARN"
                  echo "- DB Cluster: $DB_CLUSTER"
                  
                  # Attempt graceful terraform destroy if state exists
                  if terraform state list > /dev/null 2>&1; then
                    echo "๐ฅ Attempting Terraform destroy..."
                    terraform destroy -input=false -auto-approve \
                      -var "deploy_database=${DEPLOY_DATABASE}" \
                      -var "deploy_web=${DEPLOY_WEB}" \
                      -var "deploy_monitoring=${DEPLOY_MONITORING}" \
                      -var "db_master_password=${TF_DB_PASSWORD}" || echo "โ๏ธ Terraform destroy failed, continuing with manual cleanup..."
                  fi
                  
                  # Manual cleanup of specific resources if terraform destroy failed
                  echo "๐งน Manual cleanup of remaining resources..."
                  
                  # Cleanup Database Cluster (most expensive to leave running)
                  if [ "$DB_CLUSTER" != "None" ] && [ "$DB_CLUSTER" != "null" ]; then
                    echo "๐๏ธ Deleting RDS cluster: $DB_CLUSTER"
                    aws rds delete-db-cluster --db-cluster-identifier "$DB_CLUSTER" --skip-final-snapshot --delete-automated-backups 2>/dev/null || echo "Could not delete DB cluster"
                  fi
                  
                  # Cleanup Load Balancer
                  if [ "$ALB_ARN" != "None" ] && [ "$ALB_ARN" != "null" ]; then
                    echo "โ๏ธ Deleting Load Balancer: $ALB_ARN"
                    aws elbv2 delete-load-balancer --load-balancer-arn "$ALB_ARN" 2>/dev/null || echo "Could not delete ALB"
                  fi
                  
                  # Cleanup Auto Scaling Group
                  echo "๐ฑ Deleting Auto Scaling Group..."
                  aws autoscaling delete-auto-scaling-group --auto-scaling-group-name "capstoneproject-asg" --force-delete 2>/dev/null || echo "ASG not found or already deleted"
                  
                  # Cleanup Launch Template
                  echo "๐ Deleting Launch Template..."
                  LAUNCH_TEMPLATE_ID=$(aws ec2 describe-launch-templates --launch-template-names "capstoneproject-lt-*" --query 'LaunchTemplates[0].LaunchTemplateId' --output text 2>/dev/null || echo "None")
                  if [ "$LAUNCH_TEMPLATE_ID" != "None" ] && [ "$LAUNCH_TEMPLATE_ID" != "null" ]; then
                    aws ec2 delete-launch-template --launch-template-id "$LAUNCH_TEMPLATE_ID" 2>/dev/null || echo "Could not delete launch template"
                  fi
                  
                  # Cleanup EC2 Instances
                  echo "๐ป Terminating EC2 instances..."
                  INSTANCE_IDS=$(aws ec2 describe-instances --filters "Name=tag:Name,Values=capstoneproject-*" "Name=instance-state-name,Values=running,pending" --query 'Reservations[].Instances[].InstanceId' --output text 2>/dev/null || echo "")
                  if [ ! -z "$INSTANCE_IDS" ] && [ "$INSTANCE_IDS" != "None" ]; then
                    aws ec2 terminate-instances --instance-ids $INSTANCE_IDS 2>/dev/null || echo "Could not terminate instances"
                  fi
                  
                  # Wait a bit for resources to start cleanup
                  echo "โณ Waiting for resource deletion to begin..."
                  sleep 30
                  
                  # Cleanup NAT Gateway (has charges)
                  echo "๐ Deleting NAT Gateway..."
                  if [ "$VPC_ID" != "None" ] && [ "$VPC_ID" != "null" ]; then
                    NAT_GW_ID=$(aws ec2 describe-nat-gateways --filter "Name=vpc-id,Values=$VPC_ID" --query 'NatGateways[0].NatGatewayId' --output text 2>/dev/null || echo "None")
                    if [ "$NAT_GW_ID" != "None" ] && [ "$NAT_GW_ID" != "null" ]; then
                      aws ec2 delete-nat-gateway --nat-gateway-id "$NAT_GW_ID" 2>/dev/null || echo "Could not delete NAT gateway"
                    fi
                  fi
                  
                  echo "๐งน Emergency cleanup completed"
                  echo "โ๏ธ Please verify in AWS console that no resources are left running"
                  echo "๐ฐ This helps prevent unexpected charges"
                '''
              }
            }
          } catch (Exception cleanupError) {
            echo "โ Emergency cleanup failed: ${cleanupError.getMessage()}"
            echo "๐จ MANUAL INTERVENTION REQUIRED:"
            echo "   Please check AWS console and manually delete resources:"
            echo "   - VPC: capstoneproject-vpc"
            echo "   - RDS Cluster: capstoneproject-cluster" 
            echo "   - Load Balancer: capstoneproject-alb"
            echo "   - Auto Scaling Group: capstoneproject-asg"
            echo "   - EC2 Instances: capstoneproject-*"
            echo "   - NAT Gateway in the VPC"
          }
        }
      }
    }
    
    aborted {
      echo "๐ Pipeline was aborted by user"
      
      // Cleanup for aborted builds
      script {
        if (params.ACTION == 'install') {
          echo "๐จ ABORT CLEANUP: Pipeline was interrupted during installation"
          echo "โ๏ธ Attempting to destroy any partially created resources..."
          
          try {
            withCredentials([
              [$class: 'AmazonWebServicesCredentialsBinding', credentialsId: 'aws-credentials'],
              string(credentialsId: 'tf-db-password', variable: 'TF_DB_PASSWORD')
            ]) {
              timeout(time: 15, unit: 'MINUTES') {
                sh '''
                  echo "๐ Emergency cleanup after abort..."
                  
                  # Quick terraform destroy attempt
                  if [ -f ".terraform/terraform.tfstate" ] || [ -f "terraform.tfstate" ]; then
                    echo "๐ฅ Quick terraform destroy attempt..."
                    terraform destroy -input=false -auto-approve \
                      -var "deploy_database=true" \
                      -var "deploy_web=true" \
                      -var "deploy_monitoring=true" \
                      -var "db_master_password=${TF_DB_PASSWORD}" || echo "Terraform destroy failed"
                  fi
                  
                  # Critical resource cleanup (expensive resources first)
                  echo "๐๏ธ Checking for RDS cluster..."
                  aws rds delete-db-cluster --db-cluster-identifier "capstoneproject-cluster" --skip-final-snapshot --delete-automated-backups 2>/dev/null || echo "No RDS cluster found"
                  
                  echo "โ๏ธ Checking for Load Balancer..."
                  ALB_ARN=$(aws elbv2 describe-load-balancers --names "capstoneproject-alb" --query 'LoadBalancers[0].LoadBalancerArn' --output text 2>/dev/null || echo "None")
                  if [ "$ALB_ARN" != "None" ]; then
                    aws elbv2 delete-load-balancer --load-balancer-arn "$ALB_ARN" 2>/dev/null || echo "Could not delete ALB"
                  fi
                  
                  echo "๐ฑ Checking for Auto Scaling Group..."
                  aws autoscaling delete-auto-scaling-group --auto-scaling-group-name "capstoneproject-asg" --force-delete 2>/dev/null || echo "No ASG found"
                  
                  echo "๐งน Abort cleanup completed"
                '''
              }
            }
          } catch (Exception abortError) {
            echo "โ Abort cleanup failed: ${abortError.getMessage()}"
            echo "๐จ Please manually check AWS console for remaining resources"
          }
        }
      }
    }
    
    unstable {
      echo "โ๏ธ Pipeline completed with warnings"
    }
  }
}